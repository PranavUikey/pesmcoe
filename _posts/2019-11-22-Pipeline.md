---
layout: page
title: Pipeline
permalink: /pipeline/
featured-img: tensorflow_playground
summary: The complete workflow of a machine learning project.
---

# Machine learning project pipeline
## Steps involved in the pipeline
1. [Gathering Data.](#gathering-data)
2. [Data Preparation.](#data-preparation)
3. [Finding the best model.](#finding-the-best-model)
4. [Training.](#training)
5. [Evaluation.](#evaluation)
6. [Tuning.](#tuning)
7. [Predictions.](#predictions)

Let us walk through all the steps in this pipeline using an example - A Dogs vs Cats classifier!

### Gathering Data

![Dogs vs Cats]({{ site.baseurl }}/assets/img/Pipeline/Dog_vs_Cat.jpg)

The first step in any machine learning/data science project is always gathering the data. This is a very important aspect of the entire process and a lot of times the quality of the model has a very large dependency on the quality of the data gathered. You have to make sure that the data is not skewed in any way and contains pictures of all the different breeds of cats as well as dogs. There are multiple ways through which you can gather data:
- Find freely available online datasets. This is the most common approach which you will use while studying machine learning. There are several amazing places where you can find data like [Kaggle](https://www.kaggle.com/), UCI Machine learning [datasets](https://archive.ics.uci.edu/ml/datasets.php)
- Scrape the web for images. If you don't find any online dataset or if you just need some more data, web scraping is a handy tool that will help you out. Using python, web scraping is very easy through libraries like [Beatiful Soup](https://www.crummy.com/software/BeautifulSoup/), [scrapy](https://scrapy.org/) and many more!
- Manually take pictures of cats and dogs :)

### Data Preparation
![Data preparation]({{ site.baseurl }}/assets/img/Pipeline/person-pointing.jpg)

The gathered data is not always directly in a usable state. First, the data is cleaned where multiple operations can be carried out. Data cleaning consists of the following steps:
- Fixing corrupt or broken images. This can be done by using some algorithm which can recover corrupt data or by simply deleting these images. 
- The images may also be converted to grayscale to improve our model's performance. This reduces the size of the image while in this case maintaining performance. 
- Scaling and normalizing the data. This has shown to improve performance in different types of tasks and makes it easier for the model to work with your data. 
- Resizing the images to a fixed size. Our model is going to be static. This means that it is going to have a predefined number of inputs and outputs. So we will fix the size of the input and resize all the input images. 
- Dividing the dataset into training, testing and validation. This is done so that our training data is different from our testing data. The training data is the data used by the model while training. In a supervised learning approach, the correct answer is provided along with this data to the model for the model to be able to train. This is the reason why the training data has to be different from the unseen test data which tells you how well the model can generalize on new data. For our example, the training data will contain images of cats and dogs, with their associated labels. These images along with their labels will be given to the model during training. The model will then be tested on the test data where the model's predictions will be checked with the true label of the image.

Some very popular libraries to process and clean your data while finding meaningful insights are: [pandas](https://pandas.pydata.org/), [matplotlib](https://matplotlib.org/), [numpy](https://numpy.org/), [seaborn](https://seaborn.pydata.org/) and many many more.

### Finding the best model

The [No Free Lunch (NFL)](https://en.wikipedia.org/wiki/No_free_lunch_in_search_and_optimization) theorem states that no one model works best for every problem. Different types of models work well for different kinds of data with different required outputs. This is a very important process as you have to research and find the best algorithm (sometimes a combination of multiple algorithms) for your problem. For a classification task, you may use a Support Vector Machine (SVM) or a Neural Network or any other classifier. For a problem like cats vs dogs classifier, you may want to use a specific type of neural network called a Convolutional Neural Network (CNN).

### Training

Here, we proceed to provide the data to the model and let it train. This part of the process is generally very time consuming especially for large datasets and deep model architectures. It is very important to write parallel algorithms or use libraries like [sklearn](https://scikit-learn.org/stable/), [tensorflow](https://www.tensorflow.org/), [pytorch](https://pytorch.org/) etc. to create the model. These libraries contain algorithms implemented with parallelism in mind and may also make use of a Graphics Processing Unit (GPU) if available. GPU's are capable of large scale parallel processing and may reduce your training time significantly. You can keep the model for training and go out for a cup of coffee!

### Evaluation

Once the model is trained, finding out how well it does on unseen data is called evaluation. If your evaluation metrics differ significantly from your training metrics, it is a sign of either overfitting to the training data, incorrect model hyperparameters or skewed training data. 

### Tuning
This is the part where you fine-tune the hyperparameters of your machine learning model and repeat the training process. A very common approach to this method is iteratively decreasing the learning rate during the fine-tuning process. Fine-tuning is popularly used during transfer learning and has been shown to reduce the training time significantly while producing state of the art results.


### Predictions

You are done! This is the last step where you have a fully working model ready to make predictions!

### Additional reading

These are some really helpful articles that I found online which will help you understand more about this topic. 
- [The 7 steps of a machine learning project](https://towardsdatascience.com/the-7-steps-of-machine-learning-2877d7e5548e)
- [Workflow of a machine learning project](https://towardsdatascience.com/workflow-of-a-machine-learning-project-ec1dba419b94)

## Want to learn more?

We have a fantastic course here at AI Adventures! If you like the way the python course is being held, you will definitely enjoy the machine learning course. Feel free to contact us anytime if you have any questions regarding the blog or the machine learning [course](https://aiadventures.in/machine-learning/) :)
